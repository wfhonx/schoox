{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f6d2ab1-8fd9-42ba-b9f1-796250420334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19fbd2a5-fb40-49f0-a4b7-e6d7465ff953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df855440-00a4-4f5c-95eb-5bac9841f701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Constants ===\n",
    "ACADEMY_ID = \"academy_id\"\n",
    "API_KEY = \"api_key\"\n",
    "BASE_URL = \"https://app.ca.schoox.com/api/v1\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"apikey\": API_KEY,\n",
    "    \"acadId\": ACADEMY_ID\n",
    "}\n",
    "\n",
    "GET_USER_LIMIT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caaad426-0866-435e-93e4-b77425ae0ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========= Main api call function =========\n",
    "\n",
    "def get_response_json(request, parameters=None):\n",
    "    ENDPOINT = f\"{BASE_URL}/{request}\"\n",
    "    if parameters == None:\n",
    "        parameters = PARAMS\n",
    "    else:\n",
    "        parameters.update(PARAMS)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(ENDPOINT, params=parameters)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return json.loads(response.text)\n",
    "        else:\n",
    "            for i in range(5):\n",
    "                sleep(3)\n",
    "                response = requests.get(ENDPOINT, params=parameters)\n",
    "                if response.status_code == 200:\n",
    "                    return json.loads(response.text)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            print(f\"❌ Error: {response.status_code}: {response.text}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ Request failed: {e}\")\n",
    "\n",
    "# ==================================================================================\n",
    "\n",
    "\n",
    "def generate_groups():\n",
    "    types_df = pd.DataFrame(get_response_json(\"types\"))                         # superset types\n",
    "    types_df.rename(columns={\"id\":\"type_id\", \"name\":\"type_name\"}, inplace=True)\n",
    "\n",
    "    aboves_df = pd.DataFrame(get_response_json(\"aboves\",{\"limit\":1000}))        # supersets\n",
    "    aboves_df = aboves_df.iloc[:,0:3]\n",
    "\n",
    "    groups = aboves_df.merge(types_df, on=\"type_id\", suffixes=(\"_aboves\", \"_type\"))\n",
    "    groups_df = groups[~groups[\"type_name\"].isin([\"All Users\",\"Manager\", \"Organization\"])]\n",
    "\n",
    "    return groups_df\n",
    "\n",
    "\n",
    "def extract_dept(dict_list):\n",
    "    if len(dict_list) > 0:\n",
    "        return dict_list[0]['name']\n",
    "    else: \n",
    "        return ''\n",
    "\n",
    "def extract_worker_type(dict_list, groups_df):\n",
    "    worker_types = list(groups_df[groups_df['type_name']=='Type (Safety)']['name'])\n",
    "    for i in [d['name'] for d in dict_list]:\n",
    "        if i in worker_types:\n",
    "            return i\n",
    "\n",
    "def extract_company(dict_list, groups_df):\n",
    "    companies = list(groups_df[groups_df['type_name']=='Company']['name'])\n",
    "    for i in [d['name'] for d in dict_list]:\n",
    "        if i in companies:\n",
    "            return i\n",
    "\n",
    "# Final function\n",
    "def get_all_users():\n",
    "    print(\"\\n⚙️ Fetching full user data.\")\n",
    "    parameters = {\"limit\":GET_USER_LIMIT}\n",
    "    parameters.update(PARAMS)\n",
    "    \n",
    "    response_json = get_response_json(\"users\", parameters)\n",
    "    data_df = pd.DataFrame(response_json)\n",
    "    \n",
    "    data_df['worker_type'] = \"\"\n",
    "    data_df['company'] = \"\"\n",
    "    \n",
    "    groups = generate_groups()\n",
    "    \n",
    "    for i in range(len(data_df)):\n",
    "        data_df.loc[i, 'worker_type'] = extract_worker_type(data_df['above_units'][i], groups)\n",
    "        data_df.loc[i, 'company'] = extract_company(data_df['above_units'][i], groups)\n",
    "    \n",
    "    data_df['units'] = data_df['units'].apply(extract_dept)\n",
    "    print(\"✅ User data loaded.\")\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_depts():\n",
    "    response_json = get_response_json(\"units\")\n",
    "    \n",
    "    data_df = pd.DataFrame(response_json)\n",
    "    \n",
    "    return data_df.iloc[:,0:2]\n",
    "\n",
    "\n",
    "def extract_names(dict_item):\n",
    "    return f\"{dict_item['firstname']} {dict_item['lastname']}\"\n",
    "\n",
    "def extract_categories(dict_list):\n",
    "    return [d['name'] for d in dict_list]\n",
    "\n",
    "# Final function\n",
    "def get_all_courses():\n",
    "    print(\"\\n⚙️ Fetching full course data.\")\n",
    "    parameters = {\"limit\":100, \"start\":0}\n",
    "    parameters.update(PARAMS)\n",
    "    response_json = get_response_json(\"courses\", parameters)\n",
    "    data_df = pd.DataFrame(response_json)\n",
    "\n",
    "    while len(response_json) > 0:\n",
    "        parameters[\"start\"] += 100\n",
    "        response_json = get_response_json(\"courses\", parameters)\n",
    "        data_df = pd.concat([data_df, pd.DataFrame(response_json)], ignore_index=True)\n",
    "\n",
    "    data_df['categories'] = data_df['categories'].apply(extract_categories)\n",
    "    data_df['instructor'] = data_df['instructor'].apply(extract_names)\n",
    "    data_df['categories'] = data_df['categories'].apply(lambda x: ', '.join(x)).apply(lambda x: x.replace('-', ', '))\n",
    "\n",
    "    print(\"✅ Course data loaded.\")\n",
    "\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_user_details(user_id:str, parameters=None):\n",
    "    if parameters != None:\n",
    "        parameters.update(PARAMS)\n",
    "    \n",
    "    response_json = get_response_json(f\"users/{user_id}\", parameters)\n",
    "    \n",
    "    data_df = pd.DataFrame(response_json)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_user_course_details(user_id:str, parameters=None):\n",
    "    if parameters != None:\n",
    "        parameters.update(PARAMS)\n",
    "    else:\n",
    "        parameters = {\"userId\": user_id}\n",
    "    \n",
    "    response_json = get_response_json(\"courses\", parameters)\n",
    "    \n",
    "    data_df = pd.DataFrame(response_json)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_user_progress(user_id):\n",
    "    \n",
    "    response_json = get_response_json(f\"dashboard/users/{user_id}/courses\")\n",
    "    data_df = pd.DataFrame(response_json)\n",
    "    data_df['user_id'] = user_id\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\n",
    "# Final function\n",
    "def get_all_progress():\n",
    "    print(\"\\n⚙️ Fetching full progress data.\")\n",
    "    cols = [\n",
    "            'user_id','id','title','url','progress','total_time','due_date','is_due',\n",
    "            'last_progress','completions_count','completed_by_admin','assignee_first_name',\n",
    "            'assignee_last_name','enroll_date','timecompleted','certificates','enrolled',\n",
    "            'archived','completed_as_equivalent','external_id','required','compliance_course'\n",
    "            ]\n",
    "    data_df = pd.DataFrame(columns=cols)\n",
    "    id_list = [d['id'] for d in get_response_json(\"users\", {'limit':GET_USER_LIMIT})]\n",
    "    print(f\"User count: {len(id_list)}\")\n",
    "    \n",
    "    for id in tqdm(id_list):\n",
    "        try:\n",
    "            response = get_response_json(f\"dashboard/users/{id}/courses\")\n",
    "            if response != []:\n",
    "                response_df = pd.DataFrame(response)\n",
    "                response_df['user_id'] = id\n",
    "                data_df = pd.concat([data_df, response_df], ignore_index=True)\n",
    "        except Exception as E:\n",
    "            print(f\"{id}: {E}\")\n",
    "    \n",
    "    print(\"✅ Progress data loaded.\")\n",
    "\n",
    "    return data_df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f032029-c619-4d7e-a785-ca35a8593b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "users = get_all_users()\n",
    "\n",
    "courses = get_all_courses()\n",
    "\n",
    "progress = get_all_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c5100a-b620-4e73-b094-5e3f514be75a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#progress.to_csv('progress.csv')\n",
    "#spark_df = spark.createDataFrame(df, schema=SCHEMA)\n",
    "#spark_df.write.format(\"delta\").option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(delta_table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Schoox",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
